# 对象检测

## 场景

- 多个类别（不固定）
- 多个目标位置（不固定）；

## 方案1：Detection as Classification

把回归当成分类，扫描框即定位，需要遍历探测许多位置、许多尺度，最终进行合并形成定位。

### 发展

- 2005年，HOG，方向梯度直方图，用快速的线性分类器进行多位置、多尺度检测，应用NMS，Dalal and Triggs，“Histograms of Oriented Gradients for Human Detection”, CVPR 2005 Slide credit: Ross Girshick；
- 2010年，DPM，Deformable Parts Model；

## 方案2：Region Proposals

不全部遍历，只查看一些有可能的区域，通过图像像素级别的相似特征，不进行分类识别，只输出大量的目标框。

### 方法
		
- Selective Search，从像素出发，合并相似region，Convert regions to boxes，并在不同尺度上进行操作，可产生大量的候选区域，Uijlings et al, “Selective Search for Object Recognition”, IJCV 2013；		
- EdgeBoxes，另一种优秀方法，Hosang et al, “What makes for effective detection proposals?”, PAMI 2015；

### 特点：

- 速度快，每张图片3秒~10秒；

## 方案3：R-CNN

R-CNN，Regions with CNN features，将候选区域搜索与CNN结合。
		
2014年，R-CNN，先由a Proposal method产生2K个RoI(Regions of Interest)，然后进行SVM分类+回归定位操作。

Girschick et al, “Rich feature hierarchies for accurate object detection and semantic segmentation”, CVPR 2014。

### 训练步骤

1. 训练CNN分类模型，或者用训练好的AlexNet；
2. 替换CNN的最后一层全连接层，改为输出21个目标类别（20类对象+1类背景），用基于检测集产生的正、负片进行分类训练；
3. 遍历检测集每张图片的每个候选区域，用第2部训练好的CNN进行特征提取，然后保存到disk；
4. 将特征用于分别训练BBox和SVM；

### 基于检测集Pascal VOC的训练

1. 检测集上的图片中可能有多个对象，以及各自的BBox；
2. selective search算法产生的框是训练之外的独立算法产生的，不能进行优化调整；
3. Fine-Tune CNN时，目标是训练21类的分类器；
4. Fine-Tune CNN时，是以selective search产生的region作为训练集的，这些region一开始并没有label，于是用IoU>0.5为正样本，否则为负样本（背景）的方式，通过对比Pascal VOC原始图片标注，获得了label，这样一方面可以训练出背景类，一方面相当于进行了数据集增强；
5. 对所有图片的所有Region，用CNN提取fc7的4096维特征，用于训练SVM；
6. 在SVM时，会对每个4096维特征，重新打label，负样本label依然是通过IoU的方式，IoU<0.3，但是正样本就是直接用原始BBox（比之前严格了），SVM训练数据量不用那么大；
7. 为每个类都训练一个二分类的SVM；

### 缺点：

- 训练过程复杂，点对点目标训练；
- 训练慢，占用大量磁盘空间；
- 检测慢，基于VGG16每张图片需要47秒；

### 问题：

1. **如何精修边框**？ 
2. BBox的精度如何测量？
3. SS算法细节？
4. **TensorFlow如何做fine-tune**？

## 方案4：Fast R-CNN

Girschick, “Fast R-CNN”, ICCV 2015。

### 技术特点

- ROI Pooling；
- 同时训练基于CNN的分类器和BBox回归；

### ROI Pooling

1. ROI Pooling层的输入是两个来源，卷积层的feature map和ss产生的框；
2. 对于不同大小的框的feature maps，通过ROI Pooling，对每个框进行m x n划分，然后进行max pooling，最后输出大小相同的m x n的feature maps；

### 问题：

1. **联合loss实现？反向传播如何做**？

## 方案5：Faster R-CNN

在2015年中期，一个微软研究员的团队 Shaoqing Ren，Kaiming He，Ross Girshick 和 Jian Sun，找到了一个方法来解决这个瓶颈问题，他们将这个方法命名为 Faster R-CNN。

Ren et al, “Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks”, NIPS 2015。

### RPN，Region Proposal Network

- 基于FCN，Fully Conv Network；

### RPN算法

1. 生成锚框（anchor box）；
2. 通过回归来进行修正；
3. 通过独立的softmax分类来决定是否是有效目标（不会分更具体的类别）；
4. 输出有效的目标框；

## 方案6：YOLO

特点：

结构：

- 基础CNN：GoogleNet（Inception Module有所简化）；
- 有全连接层；

## 方案7：SSD（Single Shot）

单发多框检测器；

特点：

- 具有同YOLO将detection转化为regression的思路；
- 具有同Faster RCNN中anchor box类似的prior box；
- 加入特征金字塔（Pyramidal Feature Hierarchy）；

结构：

- VGG16；
- FCN；

### 如何生成anchor box

- 可以以每个像素为中心都生成；
- 分类器有N+1（背景）类；

## 方案8：YOLO 9000 & YOLO v2

CVPR 2017 YOLO 9000。